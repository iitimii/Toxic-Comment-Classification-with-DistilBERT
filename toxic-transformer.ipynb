{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-20T14:46:57.418250Z","iopub.status.busy":"2023-07-20T14:46:57.417860Z","iopub.status.idle":"2023-07-20T14:47:11.584484Z","shell.execute_reply":"2023-07-20T14:47:11.583442Z","shell.execute_reply.started":"2023-07-20T14:46:57.418223Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]}],"source":["#Importing Dependencies\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from sklearn import metrics\n","import transformers\n","import torch\n","import torch.nn as nn\n","\n","from torch.utils.data import Dataset, DataLoader \n","from transformers import DistilBertTokenizer, DistilBertModel\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:11.588492Z","iopub.status.busy":"2023-07-20T14:47:11.587018Z","iopub.status.idle":"2023-07-20T14:47:11.626595Z","shell.execute_reply":"2023-07-20T14:47:11.625275Z","shell.execute_reply.started":"2023-07-20T14:47:11.588462Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Current device: cuda\n"]}],"source":["#Setting up device\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.has_mps:\n","    device = torch.device('mps')\n","else:\n","    device = torch.device('cpu')\n","\n","print(f\"Current device: {device}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:11.631337Z","iopub.status.busy":"2023-07-20T14:47:11.631020Z","iopub.status.idle":"2023-07-20T14:47:11.637776Z","shell.execute_reply":"2023-07-20T14:47:11.637046Z","shell.execute_reply.started":"2023-07-20T14:47:11.631303Z"},"trusted":true},"outputs":[],"source":["#Key Parameters\n","\n","MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 32\n","EPOCHS = 2\n","LEARNING_RATE = 1e-05"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:11.640213Z","iopub.status.busy":"2023-07-20T14:47:11.639057Z","iopub.status.idle":"2023-07-20T14:47:13.202002Z","shell.execute_reply":"2023-07-20T14:47:13.200961Z","shell.execute_reply.started":"2023-07-20T14:47:11.640179Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Samples : 159571\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Loading Training data\n","\n","train_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n","print(f\"Total Samples : {len(train_data)}\")\n","\n","train_data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:13.206416Z","iopub.status.busy":"2023-07-20T14:47:13.206113Z","iopub.status.idle":"2023-07-20T14:47:13.610425Z","shell.execute_reply":"2023-07-20T14:47:13.609349Z","shell.execute_reply.started":"2023-07-20T14:47:13.206366Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>[0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text              labels\n","0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n","1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n","2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n","3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n","4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Removing id column and preparing labels into the single list column\n","\n","train_data.drop(['id'], inplace=True, axis=1)\n","train_data['labels'] = train_data.iloc[:, 1:].values.tolist()\n","train_data.drop(train_data.columns.values[1:-1].tolist(), inplace=True, axis=1)\n","train_data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:13.614285Z","iopub.status.busy":"2023-07-20T14:47:13.613244Z","iopub.status.idle":"2023-07-20T14:47:16.038566Z","shell.execute_reply":"2023-07-20T14:47:16.037534Z","shell.execute_reply.started":"2023-07-20T14:47:13.614245Z"},"trusted":true},"outputs":[],"source":["# Data Cleaning\n","# Lower case\n","# Remove extra space\n","\n","train_data[\"comment_text\"] = train_data[\"comment_text\"].str.lower()\n","train_data[\"comment_text\"] = train_data[\"comment_text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \")\n","train_data['labels'] = train_data['labels'].apply(lambda x: np.array(x))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:16.040581Z","iopub.status.busy":"2023-07-20T14:47:16.040188Z","iopub.status.idle":"2023-07-20T14:47:16.077640Z","shell.execute_reply":"2023-07-20T14:47:16.076708Z","shell.execute_reply.started":"2023-07-20T14:47:16.040544Z"},"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(train_data['comment_text'], train_data['labels'],test_size=0.2)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:16.079402Z","iopub.status.busy":"2023-07-20T14:47:16.078954Z","iopub.status.idle":"2023-07-20T14:47:18.409704Z","shell.execute_reply":"2023-07-20T14:47:18.408701Z","shell.execute_reply.started":"2023-07-20T14:47:16.079353Z"},"trusted":true},"outputs":[],"source":["y_train = np.array(y_train.tolist())\n","y_test = np.array(y_test.tolist())\n","X_train = np.array(X_train.tolist())\n","X_test = np.array(X_test.tolist())"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:18.411689Z","iopub.status.busy":"2023-07-20T14:47:18.411286Z","iopub.status.idle":"2023-07-20T14:47:18.424154Z","shell.execute_reply":"2023-07-20T14:47:18.423060Z","shell.execute_reply.started":"2023-07-20T14:47:18.411652Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([12259,  1296,  6778,   385,  6340,  1131])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["y_train.sum(axis=0)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:18.426365Z","iopub.status.busy":"2023-07-20T14:47:18.425652Z","iopub.status.idle":"2023-07-20T14:47:18.676269Z","shell.execute_reply":"2023-07-20T14:47:18.674931Z","shell.execute_reply.started":"2023-07-20T14:47:18.426328Z"},"trusted":true},"outputs":[],"source":["# Creating a dataset class that outputs the token id, token mask, and token type id of the required sentence\n","\n","class MultiLabelDataset(Dataset):\n","\n","    def __init__(self, X, y, tokenizer, max_len):\n","        self.text = X\n","        self.target = y\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        target = self.target[index]\n","        text = str(self.text[index])\n","        # text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        \n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","        output = {\n","            'ids': torch.tensor(ids, dtype=torch.float32),\n","            'mask': torch.tensor(mask, dtype=torch.float32),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.float32),\n","            'target': torch.tensor(target, dtype=torch.float32)\n","         }\n","                \n","        return output"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:18.678132Z","iopub.status.busy":"2023-07-20T14:47:18.677577Z","iopub.status.idle":"2023-07-20T14:47:19.692558Z","shell.execute_reply":"2023-07-20T14:47:19.691580Z","shell.execute_reply.started":"2023-07-20T14:47:18.678097Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa6eb75c54bf471fbfb6b40ca10d6cb6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef9a7572bc2b4bdfa7914d2a6521edf7","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e179bc7eaeef40c58fdf413a36ee8700","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Creating tokenizer object\n","# Creating dataset object\n","#Creating dataloader for the dataset\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\n","\n","train_set = MultiLabelDataset(X_train, y_train, tokenizer, MAX_LEN)\n","train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n","\n","test_set = MultiLabelDataset(X_test, y_test, tokenizer, MAX_LEN)\n","test_loader = DataLoader(test_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:19.694521Z","iopub.status.busy":"2023-07-20T14:47:19.694140Z","iopub.status.idle":"2023-07-20T14:47:19.702331Z","shell.execute_reply":"2023-07-20T14:47:19.701038Z","shell.execute_reply.started":"2023-07-20T14:47:19.694487Z"},"trusted":true},"outputs":[],"source":["#Creating the custom DistilBERT model class\n","\n","class DistilBERTClass(nn.Module):\n","    \n","    def __init__(self):\n","        super(DistilBERTClass, self).__init__()\n","        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = nn.Dropout(0.2)\n","        self.classifier = nn.Linear(768, 6)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = nn.Tanh()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:19.704952Z","iopub.status.busy":"2023-07-20T14:47:19.704091Z","iopub.status.idle":"2023-07-20T14:47:26.143257Z","shell.execute_reply":"2023-07-20T14:47:26.142199Z","shell.execute_reply.started":"2023-07-20T14:47:19.704809Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10dbbf57bf0444be9eae4dabf4192c49","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["DistilBERTClass(\n","  (l1): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#Creating model object\n","\n","model = DistilBERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:26.148034Z","iopub.status.busy":"2023-07-20T14:47:26.147725Z","iopub.status.idle":"2023-07-20T14:47:26.154116Z","shell.execute_reply":"2023-07-20T14:47:26.152573Z","shell.execute_reply.started":"2023-07-20T14:47:26.148007Z"},"trusted":true},"outputs":[],"source":["loss_fn = torch.nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:26.156451Z","iopub.status.busy":"2023-07-20T14:47:26.155691Z","iopub.status.idle":"2023-07-20T14:47:26.170490Z","shell.execute_reply":"2023-07-20T14:47:26.169494Z","shell.execute_reply.started":"2023-07-20T14:47:26.156369Z"},"trusted":true},"outputs":[],"source":["def train(epochs):\n","    mean_loss = 0\n","    mean_val_loss = 0\n","    step = 0\n","    val_step = 1\n","    print(f'Training for {epochs} epoch(s)')\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        for data in tqdm(train_loader):\n","            step+=1\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['target'].to(device, dtype = torch.float)\n","\n","            outputs = model(ids, mask, token_type_ids)\n","\n","            optimizer.zero_grad()\n","            loss = loss_fn(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            mean_loss += loss.item()\n","            \n","        model.eval()\n","        with torch.inference_mode():\n","            for val_data in tqdm(test_loader):\n","                val_step+=1\n","                val_ids = val_data['ids'].to(device, dtype = torch.long)\n","                val_mask = val_data['mask'].to(device, dtype = torch.long)\n","                val_token_type_ids = val_data['token_type_ids'].to(device, dtype = torch.long)\n","                val_targets = val_data['target'].to(device, dtype = torch.float)\n","\n","                val_outputs = model(val_ids, val_mask, val_token_type_ids)\n","\n","                val_loss = loss_fn(val_outputs, val_targets)\n","                mean_val_loss+=val_loss.item()\n","                \n","        mean_loss /= step\n","        mean_val_loss /= val_step\n","        print(f'Epoch: {epoch}, Loss:  {mean_loss}, Val_Loss:  {mean_val_loss}')\n","        torch.save(model.state_dict(), 'model_checkpoint.pth')\n","        \n","    torch.save(model.state_dict(), f'model_{mean_val_loss:.3f}.pth')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T14:47:26.172501Z","iopub.status.busy":"2023-07-20T14:47:26.172158Z","iopub.status.idle":"2023-07-20T15:58:05.101196Z","shell.execute_reply":"2023-07-20T15:58:05.100145Z","shell.execute_reply.started":"2023-07-20T14:47:26.172470Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training for 2 epoch(s)\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/3990 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","100%|██████████| 3990/3990 [31:36<00:00,  2.10it/s]\n","100%|██████████| 998/998 [03:41<00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Loss:  0.05238986257393669, Val_Loss:  0.03887622743167703\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 3990/3990 [31:37<00:00,  2.10it/s]\n","100%|██████████| 998/998 [03:40<00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Loss:  0.01756992314089262, Val_Loss:  0.01843887561265496\n"]}],"source":["train(EPOCHS)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-07-20T15:58:05.369654Z","iopub.status.busy":"2023-07-20T15:58:05.369064Z","iopub.status.idle":"2023-07-20T15:58:05.375247Z","shell.execute_reply":"2023-07-20T15:58:05.374138Z","shell.execute_reply.started":"2023-07-20T15:58:05.369618Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["five\n"]}],"source":["print('five')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
